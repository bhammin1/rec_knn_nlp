{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\12693\\Documents\\JHU\\AI-Enabling Systems\\research\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)e9125/.gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 1.18MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<?, ?B/s] \n",
      "Downloading (…)7e55de9125/README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 2.66MB/s]\n",
      "Downloading (…)55de9125/config.json: 100%|██████████| 612/612 [00:00<?, ?B/s] \n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 115kB/s]\n",
      "Downloading (…)125/data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 19.6MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:04<00:00, 21.9MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<?, ?B/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 112kB/s]\n",
      "Downloading (…)e9125/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 8.36MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 350/350 [00:00<?, ?B/s] \n",
      "Downloading (…)9125/train_script.py: 100%|██████████| 13.2k/13.2k [00:00<00:00, 4.41MB/s]\n",
      "Downloading (…)7e55de9125/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 28.0MB/s]\n",
      "Downloading (…)5de9125/modules.json: 100%|██████████| 349/349 [00:00<00:00, 173kB/s]\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6003]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences1 = [\"I'm happy\", \"I'm full of happiness\"]\n",
    "#Compute embedding for both lists\n",
    "embedding_1= model.encode(sentences1[0], convert_to_tensor=True)\n",
    "embedding_2 = model.encode(sentences1[1], convert_to_tensor=True)\n",
    "\n",
    "util.pytorch_cos_sim(embedding_1, embedding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8939]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences3 = 'The new movie is awesome'\n",
    "sentence4 = 'The new movie is so great'\n",
    "#Compute embedding for both lists\n",
    "embedding_3= model.encode(sentences3, convert_to_tensor=True)\n",
    "embedding_4 = model.encode(sentence4, convert_to_tensor=True)\n",
    "score = util.pytorch_cos_sim(embedding_3, embedding_4)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89390373"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(score)\n",
    "score.numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2') call in KNN\n",
    "def semantic_text_sim(title1, title2):\n",
    "    #Compute embedding for both lists\n",
    "    embedding_1= model.encode(title1, convert_to_tensor=True)\n",
    "    embedding_2 = model.encode(title2, convert_to_tensor=True)\n",
    "    score = util.pytorch_cos_sim(embedding_1, embedding_2) # tensor returned\n",
    "    return score.numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7872645"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_text_sim(\"I always eat cheese\", \"I prefer foods with cheese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83356345"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_text_sim(\"I hate disco\", \"I love disco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\12693\\Documents\\JHU\\AI-Enabling Systems\\research\\lib\\site-packages\\scipy\\spatial\\distance.py:636: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "spatial.distance.cosine([.833], [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial.distance.cosine([.83], [0.00001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 702/702 [00:00<00:00, 704kB/s]\n",
      "c:\\Users\\12693\\Documents\\JHU\\AI-Enabling Systems\\research\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\12693\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading pytorch_model.bin: 100%|██████████| 499M/499M [00:15<00:00, 32.2MB/s] \n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 25.0/25.0 [00:00<00:00, 25.0kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 6.94MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 41.6MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 772/772 [00:00<00:00, 779kB/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "nli_model = CrossEncoder('cross-encoder/nli-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entailment', 'contradiction']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_nli = nli_model.predict([('A man is eating pizza', 'A man eats something'), ('A black race car starts up in front of a crowd of people.', 'A man is driving down a lonely road.')])\n",
    "\n",
    "#Convert scores to labels\n",
    "label_mapping = ['contradiction', 'entailment', 'neutral']\n",
    "labels = [label_mapping[score_max] for score_max in scores_nli.argmax(axis=1)]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.2572556 ,  3.5655646 ,  0.00601628],\n",
       "       [ 5.398506  , -2.89872   , -1.6895918 ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_nli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.744587"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_nli_2= nli_model.predict([(\"I always eat cheese\", \"I prefer foods with cheese\")])\n",
    "scores_nli_2[0][1] # entatilement is the middle score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7934318"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_nli_2= nli_model.predict([(\"I snack on cheese\", \"I eat cheese\")])\n",
    "scores_nli_2[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0834459"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_nli_2= nli_model.predict((\"I prefer foods with cheese\",\"I always eat cheese\"))\n",
    "scores_nli_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.3351293, -2.6727824, -1.9018666]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_nli_3 = nli_model.predict([(\"I hate disco\", \"I love disco\")])\n",
    "scores_nli_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single list of sentences\n",
    "sentences = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'I love pasta',\n",
    "             'The new movie is awesome',\n",
    "             'The cat plays in the garden',\n",
    "             'A woman watches TV',\n",
    "             'The new movie is so great',\n",
    "             'Do you like pizza?']\n",
    "\n",
    "#Compute embeddings\n",
    "embeddings = model.encode(sentences, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1392,  0.0030,  0.0470,  ...,  0.0641, -0.0163,  0.0636],\n",
       "        [ 0.0227, -0.0014, -0.0056,  ..., -0.0225,  0.0846, -0.0283],\n",
       "        [-0.1025, -0.0541,  0.0108,  ...,  0.1097,  0.0851, -0.0738],\n",
       "        ...,\n",
       "        [ 0.0054, -0.0920,  0.0140,  ...,  0.0167, -0.0086, -0.0424],\n",
       "        [-0.0842, -0.0592, -0.0010,  ..., -0.0157,  0.0764,  0.0389],\n",
       "        [-0.1047,  0.0302, -0.0049,  ...,  0.0555,  0.0570, -0.0948]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute cosine-similarities for each sentence with each other sentence\n",
    "cosine_scores = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "#Find the pairs with the highest cosine similarity scores\n",
    "pairs = []\n",
    "for i in range(len(cosine_scores)-1):\n",
    "    for j in range(i+1, len(cosine_scores)):\n",
    "        pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.0363,  0.0081, -0.0247,  0.6788,  0.1310, -0.0029,  0.0254],\n",
       "        [ 0.0363,  1.0000, -0.0368,  0.0093,  0.2105, -0.0327, -0.0136,  0.0116],\n",
       "        [ 0.0081, -0.0368,  1.0000,  0.2440,  0.0230,  0.0359,  0.2560,  0.5096],\n",
       "        [-0.0247,  0.0093,  0.2440,  1.0000,  0.0275, -0.0502,  0.8939,  0.1969],\n",
       "        [ 0.6788,  0.2105,  0.0230,  0.0275,  1.0000,  0.0629,  0.0591,  0.0900],\n",
       "        [ 0.1310, -0.0327,  0.0359, -0.0502,  0.0629,  1.0000, -0.0509,  0.0417],\n",
       "        [-0.0029, -0.0136,  0.2560,  0.8939,  0.0591, -0.0509,  1.0000,  0.1692],\n",
       "        [ 0.0254,  0.0116,  0.5096,  0.1969,  0.0900,  0.0417,  0.1692,  1.0000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': [0, 1], 'score': tensor(0.0363)},\n",
       " {'index': [0, 2], 'score': tensor(0.0081)},\n",
       " {'index': [0, 3], 'score': tensor(-0.0247)},\n",
       " {'index': [0, 4], 'score': tensor(0.6788)},\n",
       " {'index': [0, 5], 'score': tensor(0.1310)},\n",
       " {'index': [0, 6], 'score': tensor(-0.0029)},\n",
       " {'index': [0, 7], 'score': tensor(0.0254)},\n",
       " {'index': [1, 2], 'score': tensor(-0.0368)},\n",
       " {'index': [1, 3], 'score': tensor(0.0093)},\n",
       " {'index': [1, 4], 'score': tensor(0.2105)},\n",
       " {'index': [1, 5], 'score': tensor(-0.0327)},\n",
       " {'index': [1, 6], 'score': tensor(-0.0136)},\n",
       " {'index': [1, 7], 'score': tensor(0.0116)},\n",
       " {'index': [2, 3], 'score': tensor(0.2440)},\n",
       " {'index': [2, 4], 'score': tensor(0.0230)},\n",
       " {'index': [2, 5], 'score': tensor(0.0359)},\n",
       " {'index': [2, 6], 'score': tensor(0.2560)},\n",
       " {'index': [2, 7], 'score': tensor(0.5096)},\n",
       " {'index': [3, 4], 'score': tensor(0.0275)},\n",
       " {'index': [3, 5], 'score': tensor(-0.0502)},\n",
       " {'index': [3, 6], 'score': tensor(0.8939)},\n",
       " {'index': [3, 7], 'score': tensor(0.1969)},\n",
       " {'index': [4, 5], 'score': tensor(0.0629)},\n",
       " {'index': [4, 6], 'score': tensor(0.0591)},\n",
       " {'index': [4, 7], 'score': tensor(0.0900)},\n",
       " {'index': [5, 6], 'score': tensor(-0.0509)},\n",
       " {'index': [5, 7], 'score': tensor(0.0417)},\n",
       " {'index': [6, 7], 'score': tensor(0.1692)}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.8939\n",
      "The cat sits outside \t\t The cat plays in the garden \t\t Score: 0.6788\n",
      "I love pasta \t\t Do you like pizza? \t\t Score: 0.5096\n",
      "I love pasta \t\t The new movie is so great \t\t Score: 0.2560\n",
      "I love pasta \t\t The new movie is awesome \t\t Score: 0.2440\n",
      "A man is playing guitar \t\t The cat plays in the garden \t\t Score: 0.2105\n",
      "The new movie is awesome \t\t Do you like pizza? \t\t Score: 0.1969\n",
      "The new movie is so great \t\t Do you like pizza? \t\t Score: 0.1692\n",
      "The cat sits outside \t\t A woman watches TV \t\t Score: 0.1310\n",
      "The cat plays in the garden \t\t Do you like pizza? \t\t Score: 0.0900\n"
     ]
    }
   ],
   "source": [
    "#Sort scores in decreasing order\n",
    "pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "for pair in pairs[0:10]:\n",
    "    i, j = pair['index']\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], pair['score']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
