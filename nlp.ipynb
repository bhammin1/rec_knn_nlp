{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\12693\\Documents\\JHU\\AI-Enabling Systems\\research\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore STS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6003]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment with the STS transformer\n",
    "sentences1 = [\"I'm happy\", \"I'm full of happiness\"]\n",
    "#Compute embedding for both lists\n",
    "embedding_1= model.encode(sentences1[0], convert_to_tensor=True)\n",
    "embedding_2 = model.encode(sentences1[1], convert_to_tensor=True)\n",
    "\n",
    "util.pytorch_cos_sim(embedding_1, embedding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8939]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences3 = 'The new movie is awesome'\n",
    "sentence4 = 'The new movie is so great'\n",
    "#Compute embedding for both lists\n",
    "embedding_3= model.encode(sentences3, convert_to_tensor=True)\n",
    "embedding_4 = model.encode(sentence4, convert_to_tensor=True)\n",
    "score = util.pytorch_cos_sim(embedding_3, embedding_4)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89390373"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return just the result\n",
    "type(score)\n",
    "score.numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2') call in KNN\n",
    "def semantic_text_sim(title1, title2):\n",
    "    #Compute embedding for both lists\n",
    "    embedding_1= model.encode(title1, convert_to_tensor=True)\n",
    "    embedding_2 = model.encode(title2, convert_to_tensor=True)\n",
    "    score = util.pytorch_cos_sim(embedding_1, embedding_2) # tensor returned\n",
    "    return score.numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7872645"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_text_sim(\"I always eat cheese\", \"I prefer foods with cheese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83356345"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_text_sim(\"I hate disco\", \"I love disco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Distance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\12693\\Documents\\JHU\\AI-Enabling Systems\\research\\lib\\site-packages\\scipy\\spatial\\distance.py:636: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "spatial.distance.cosine([.833], [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial.distance.cosine([.83], [0.00001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore NLI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "nli_model = CrossEncoder('cross-encoder/nli-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entailment', 'contradiction']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_nli = nli_model.predict([('A man is eating pizza', 'A man eats something'), ('A black race car starts up in front of a crowd of people.', 'A man is driving down a lonely road.')])\n",
    "\n",
    "#Convert scores to labels\n",
    "label_mapping = ['contradiction', 'entailment', 'neutral']\n",
    "labels = [label_mapping[score_max] for score_max in scores_nli.argmax(axis=1)]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.2572556 ,  3.5655646 ,  0.00601628],\n",
       "       [ 5.398506  , -2.89872   , -1.6895918 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_nli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.744587"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_nli_2= nli_model.predict([(\"I always eat cheese\", \"I prefer foods with cheese\")])\n",
    "scores_nli_2[0][1] # entatilement is the middle score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7934318"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_nli_2= nli_model.predict([(\"I snack on cheese\", \"I eat cheese\")])\n",
    "scores_nli_2[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0834459"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_nli_2= nli_model.predict((\"I prefer foods with cheese\",\"I always eat cheese\"))\n",
    "scores_nli_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.3351293, -2.6727824, -1.9018666]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_nli_3 = nli_model.predict([(\"I hate disco\", \"I love disco\")])\n",
    "scores_nli_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single list of sentences\n",
    "sentences = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'I love pasta',\n",
    "             'The new movie is awesome',\n",
    "             'The cat plays in the garden',\n",
    "             'A woman watches TV',\n",
    "             'The new movie is so great',\n",
    "             'Do you like pizza?']\n",
    "\n",
    "#Compute embeddings\n",
    "embeddings = model.encode(sentences, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1392,  0.0030,  0.0470,  ...,  0.0641, -0.0163,  0.0636],\n",
       "        [ 0.0227, -0.0014, -0.0056,  ..., -0.0225,  0.0846, -0.0283],\n",
       "        [-0.1025, -0.0541,  0.0108,  ...,  0.1097,  0.0851, -0.0738],\n",
       "        ...,\n",
       "        [ 0.0054, -0.0920,  0.0140,  ...,  0.0167, -0.0086, -0.0424],\n",
       "        [-0.0842, -0.0592, -0.0010,  ..., -0.0157,  0.0764,  0.0389],\n",
       "        [-0.1047,  0.0302, -0.0049,  ...,  0.0555,  0.0570, -0.0948]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute cosine-similarities for each sentence with each other sentence\n",
    "cosine_scores = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "#Find the pairs with the highest cosine similarity scores\n",
    "pairs = []\n",
    "for i in range(len(cosine_scores)-1):\n",
    "    for j in range(i+1, len(cosine_scores)):\n",
    "        pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.0363,  0.0081, -0.0247,  0.6788,  0.1310, -0.0029,  0.0254],\n",
       "        [ 0.0363,  1.0000, -0.0368,  0.0093,  0.2105, -0.0327, -0.0136,  0.0116],\n",
       "        [ 0.0081, -0.0368,  1.0000,  0.2440,  0.0230,  0.0359,  0.2560,  0.5096],\n",
       "        [-0.0247,  0.0093,  0.2440,  1.0000,  0.0275, -0.0502,  0.8939,  0.1969],\n",
       "        [ 0.6788,  0.2105,  0.0230,  0.0275,  1.0000,  0.0629,  0.0591,  0.0900],\n",
       "        [ 0.1310, -0.0327,  0.0359, -0.0502,  0.0629,  1.0000, -0.0509,  0.0417],\n",
       "        [-0.0029, -0.0136,  0.2560,  0.8939,  0.0591, -0.0509,  1.0000,  0.1692],\n",
       "        [ 0.0254,  0.0116,  0.5096,  0.1969,  0.0900,  0.0417,  0.1692,  1.0000]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': [0, 1], 'score': tensor(0.0363)},\n",
       " {'index': [0, 2], 'score': tensor(0.0081)},\n",
       " {'index': [0, 3], 'score': tensor(-0.0247)},\n",
       " {'index': [0, 4], 'score': tensor(0.6788)},\n",
       " {'index': [0, 5], 'score': tensor(0.1310)},\n",
       " {'index': [0, 6], 'score': tensor(-0.0029)},\n",
       " {'index': [0, 7], 'score': tensor(0.0254)},\n",
       " {'index': [1, 2], 'score': tensor(-0.0368)},\n",
       " {'index': [1, 3], 'score': tensor(0.0093)},\n",
       " {'index': [1, 4], 'score': tensor(0.2105)},\n",
       " {'index': [1, 5], 'score': tensor(-0.0327)},\n",
       " {'index': [1, 6], 'score': tensor(-0.0136)},\n",
       " {'index': [1, 7], 'score': tensor(0.0116)},\n",
       " {'index': [2, 3], 'score': tensor(0.2440)},\n",
       " {'index': [2, 4], 'score': tensor(0.0230)},\n",
       " {'index': [2, 5], 'score': tensor(0.0359)},\n",
       " {'index': [2, 6], 'score': tensor(0.2560)},\n",
       " {'index': [2, 7], 'score': tensor(0.5096)},\n",
       " {'index': [3, 4], 'score': tensor(0.0275)},\n",
       " {'index': [3, 5], 'score': tensor(-0.0502)},\n",
       " {'index': [3, 6], 'score': tensor(0.8939)},\n",
       " {'index': [3, 7], 'score': tensor(0.1969)},\n",
       " {'index': [4, 5], 'score': tensor(0.0629)},\n",
       " {'index': [4, 6], 'score': tensor(0.0591)},\n",
       " {'index': [4, 7], 'score': tensor(0.0900)},\n",
       " {'index': [5, 6], 'score': tensor(-0.0509)},\n",
       " {'index': [5, 7], 'score': tensor(0.0417)},\n",
       " {'index': [6, 7], 'score': tensor(0.1692)}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.8939\n",
      "The cat sits outside \t\t The cat plays in the garden \t\t Score: 0.6788\n",
      "I love pasta \t\t Do you like pizza? \t\t Score: 0.5096\n",
      "I love pasta \t\t The new movie is so great \t\t Score: 0.2560\n",
      "I love pasta \t\t The new movie is awesome \t\t Score: 0.2440\n",
      "A man is playing guitar \t\t The cat plays in the garden \t\t Score: 0.2105\n",
      "The new movie is awesome \t\t Do you like pizza? \t\t Score: 0.1969\n",
      "The new movie is so great \t\t Do you like pizza? \t\t Score: 0.1692\n",
      "The cat sits outside \t\t A woman watches TV \t\t Score: 0.1310\n",
      "The cat plays in the garden \t\t Do you like pizza? \t\t Score: 0.0900\n"
     ]
    }
   ],
   "source": [
    "#Sort scores in decreasing order\n",
    "pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "for pair in pairs[0:10]:\n",
    "    i, j = pair['index']\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], pair['score']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject",
   "language": "python",
   "name": "myproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
